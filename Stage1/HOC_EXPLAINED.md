# Understanding the HOC Calculator: A Beginner's Guide to Language Development

## Table of Contents
1. [Introduction to Language Processing](#introduction-to-language-processing)
2. [What is Yacc/Bison?](#what-is-yaccbison)
3. [Architecture Overview](#architecture-overview)
4. [Lexical Analysis: The Lexer](#lexical-analysis-the-lexer)
5. [Syntax Analysis: The Parser](#syntax-analysis-the-parser)
6. [Expression Evaluation](#expression-evaluation)
7. [Complete Example Walkthrough](#complete-example-walkthrough)
8. [How Values Flow Through the System](#how-values-flow-through-the-system)

---

## Introduction to Language Processing

### What is a Programming Language Processor?

When you write code or mathematical expressions, the computer doesn't understand them directly. A **language processor** translates your human-readable code into actions the computer can perform.

There are two main types:
- **Compilers**: Translate entire programs into machine code before execution
- **Interpreters**: Read and execute code line by line

Our HOC (Higher Order Calculator) is a simple **interpreter** that reads mathematical expressions and evaluates them immediately.

### The Two-Stage Process

Language processing typically happens in two stages:

```mermaid
graph LR
    A[Input: 2 + 3 * 4] --> B[Lexical Analysis<br/>Lexer]
    B --> C[Tokens:<br/>NUMBER:2, PLUS, NUMBER:3, MULTIPLY, NUMBER:4]
    C --> D[Syntax Analysis<br/>Parser]
    D --> E[Parse Tree/<br/>Evaluation]
    E --> F[Output: 14]

    style A fill:#e1f5ff
    style F fill:#e1ffe1
    style B fill:#fff4e1
    style D fill:#ffe1f5
```

1. **Lexical Analysis (Lexer)**: Breaks input into meaningful pieces called "tokens"
   - Example: `2 + 3` becomes `[NUMBER(2), PLUS, NUMBER(3)]`

2. **Syntax Analysis (Parser)**: Checks if tokens follow language rules and builds a structure
   - Example: Verifies that numbers and operators are in correct order
   - Builds a tree showing operation precedence

---

## What is Yacc/Bison?

**Yacc** (Yet Another Compiler Compiler) is a tool that automatically generates parsers from grammar specifications. You write the **grammar rules**, and Yacc generates the C code for parsing.

### Why Use Yacc?

Writing parsers by hand is complex and error-prone. Yacc:
- ✅ Handles operator precedence automatically
- ✅ Manages complex grammar rules
- ✅ Generates efficient parsing code
- ✅ Handles error recovery

### The Yacc Workflow

```mermaid
graph TB
    A[Write Grammar File<br/>hoc.y] --> B[Run Yacc]
    B --> C[Generated Parser<br/>hoc.tab.c]
    C --> D[Compile with C Compiler]
    D --> E[Executable Program<br/>hoc]

    style A fill:#fff4e1
    style C fill:#e1f5ff
    style E fill:#e1ffe1
```

---

## Architecture Overview

### Components of HOC Calculator

```mermaid
graph TB
    subgraph "User Interaction"
        A[User Input:<br/>2 + 3 * 4]
    end

    subgraph "Lexical Analysis"
        B[yylex Function]
        C[Token Stream]
    end

    subgraph "Syntax Analysis"
        D[yyparse Function]
        E[Grammar Rules]
    end

    subgraph "Evaluation & Output"
        F[Semantic Actions]
        G[Output: 14]
    end

    A --> B
    B --> C
    C --> D
    D --> E
    E --> F
    F --> G

    style A fill:#e1f5ff
    style B fill:#fff4e1
    style D fill:#ffe1f5
    style G fill:#e1ffe1
```

### The Three Key Components

1. **yylex()** - The Lexer (written by programmer)
   - Reads characters from input
   - Groups them into tokens
   - Returns token types to parser

2. **yyparse()** - The Parser (generated by Yacc)
   - Receives tokens from lexer
   - Checks syntax against grammar rules
   - Executes semantic actions (calculations)

3. **Grammar Rules** - The Language Specification
   - Defines what expressions are valid
   - Specifies operator precedence
   - Contains actions for evaluation

---

## Lexical Analysis: The Lexer

### What Does the Lexer Do?

The lexer (`yylex()` function) is like a scanner that reads the input character by character and groups characters into meaningful units called **tokens**.

### Token Types in HOC

```mermaid
graph LR
    A[Input Characters] --> B{Character Type?}
    B -->|Digit or .| C[NUMBER Token]
    B -->|+ - * /| D[Operator Token]
    B -->|"(  )"| E[Parenthesis Token]
    B -->|Newline| F[End Expression]
    B -->|Space / Tab| G[Skip]

    style C fill:#e1ffe1
    style D fill:#ffe1e1
    style E fill:#fff4e1
```

### The yylex() Function Explained

```c
int yylex()
{
    int c;

    // Skip whitespace
    while ((c = getchar()) == ' ' || c == '\t');

    // Check for end of input
    if (c == EOF) return 0;

    // Handle numbers (including decimals like 3.14)
    if (c == '.' || isdigit(c))
    {
        ungetc(c, stdin);      // Put character back
        scanf("%lf", &yylval);  // Read full number into yylval
        return NUMBER;          // Tell parser: "I found a number"
    }

    // Track line numbers for error messages
    if (c == '\n') lineno++;

    // Return operators and parentheses as-is
    return c;  // Returns ASCII value ('+' returns 43, etc.)
}
```

### How yylex() Works - Step by Step

**Example Input**: `2 + 3`

```mermaid
sequenceDiagram
    participant Input as Input Stream
    participant Lexer as yylex()
    participant Parser as yyparse()

    Input->>Lexer: '2'
    Note over Lexer: Digit detected!<br/>Read full number
    Lexer->>Lexer: scanf reads "2"<br/>stores in yylval
    Lexer->>Parser: Return NUMBER token<br/>yylval = 2.0

    Input->>Lexer: ' '
    Note over Lexer: Whitespace, skip

    Input->>Lexer: '+'
    Note over Lexer: Operator character
    Lexer->>Parser: Return '+' (ASCII 43)

    Input->>Lexer: ' '
    Note over Lexer: Whitespace, skip

    Input->>Lexer: '3'
    Note over Lexer: Digit detected!
    Lexer->>Lexer: scanf reads "3"<br/>stores in yylval
    Lexer->>Parser: Return NUMBER token<br/>yylval = 3.0
```

### Key Concepts: yylval

**yylval** is a special global variable that carries the **value** of a token:
- For NUMBER tokens: holds the actual numeric value (2.0, 3.14, etc.)
- For operators: not used (the token type itself is enough)

Think of it like a mailbox:
- Lexer puts the number in the mailbox (yylval)
- Parser takes the number from the mailbox

---

## Syntax Analysis: The Parser

### What is Grammar?

A **grammar** defines the structure of valid expressions in your language. It's like the rules of a game.

### HOC Grammar Rules

```yacc
%token NUMBER
%left '+' '-'        /* Lower precedence, left-associative */
%left '*' '/'        /* Higher precedence, left-associative */

%%
list:   /* empty */
    | list '\n'
    | list expr '\n'  { printf("\t%.8g\n", $2); }
    ;

expr:  NUMBER              { $$ = $1; }
    |  expr '+' expr       { $$ = $1 + $3; }
    |  expr '-' expr       { $$ = $1 - $3; }
    |  expr '*' expr       { $$ = $1 * $3; }
    |  expr '/' expr       { $$ = $1 / $3; }
    |  '(' expr ')'        { $$ = $2; }
    ;
```

### Understanding Grammar Rules

Each rule has the form: `left_side : right_side { action }`

**Example**: `expr : expr '+' expr { $$ = $1 + $3; }`

- **Left side**: `expr` (what we're defining)
- **Right side**: `expr '+' expr` (the pattern to match)
- **Action**: `{ $$ = $1 + $3; }` (what to do when matched)

### The Dollar Sign Notation

In actions, `$` refers to values of matched symbols:

```
expr : expr '+' expr  { $$ = $1 + $3; }
       |     |    |
       $1    $2   $3

       $1 = value of first expr
       $2 = value of '+' (not used here)
       $3 = value of second expr
       $$ = result to return
```

### Operator Precedence

```mermaid
graph TB
    A[Highest Precedence] --> B["* /"]
    B --> C["+ -"]
    C --> D["( ) - Parentheses override everything"]

    style A fill:#ff6b6b
    style B fill:#ffd93d
    style C fill:#6bcf7f
    style D fill:#4d96ff
```

The `%left` declarations tell Yacc:
- `*` and `/` bind tighter than `+` and `-`
- Operations at same level go left-to-right: `8 - 3 - 2` = `(8 - 3) - 2` = `3`

---

## Expression Evaluation

### How the Parser Evaluates Expressions

The parser builds a **parse tree** and evaluates it bottom-up.

### Example: Evaluating `2 + 3 * 4`

**Step 1: Lexer produces tokens**
```
NUMBER(2) → '+' → NUMBER(3) → '*' → NUMBER(4) → '\n'
```

**Step 2: Parser builds and evaluates tree**

```mermaid
graph TD
    A["expr = 14<br/>(+ operation)"] --> B["expr = 2<br/>(NUMBER)"]
    A --> C["+"]
    A --> D["expr = 12<br/>(* operation)"]
    D --> E["expr = 3<br/>(NUMBER)"]
    D --> F["*"]
    D --> G["expr = 4<br/>(NUMBER)"]

    style A fill:#e1ffe1
    style B fill:#e1f5ff
    style D fill:#fff4e1
    style E fill:#e1f5ff
    style G fill:#e1f5ff
```

**Evaluation Order** (bottom-up):

1. **Match**: `NUMBER` → `expr` with value 2
   ```
   Rule: expr : NUMBER { $$ = $1; }
   Result: expr = 2
   ```

2. **Match**: `NUMBER` → `expr` with value 3
   ```
   Rule: expr : NUMBER { $$ = $1; }
   Result: expr = 3
   ```

3. **Match**: `NUMBER` → `expr` with value 4
   ```
   Rule: expr : NUMBER { $$ = $1; }
   Result: expr = 4
   ```

4. **Match**: `expr '*' expr` (3 * 4)
   ```
   Rule: expr : expr '*' expr { $$ = $1 * $3; }
   $1 = 3, $3 = 4
   Result: $$ = 3 * 4 = 12
   ```

5. **Match**: `expr '+' expr` (2 + 12)
   ```
   Rule: expr : expr '+' expr { $$ = $1 + $3; }
   $1 = 2, $3 = 12
   Result: $$ = 2 + 12 = 14
   ```

6. **Match**: `list expr '\n'` (print result)
   ```
   Rule: list : list expr '\n' { printf("\t%.8g\n", $2); }
   $2 = 14
   Action: Print "14"
   ```

### Why Does `*` Happen Before `+`?

Because of the precedence declarations:
```yacc
%left '+' '-'    /* Declared first = lower precedence */
%left '*' '/'    /* Declared second = higher precedence */
```

Yacc ensures higher precedence operators are reduced (evaluated) first.

---

## Complete Example Walkthrough

Let's trace the complete execution of: `(2 + 3) * 4`

### Step-by-Step Execution

```mermaid
sequenceDiagram
    participant User
    participant Lexer as yylex()
    participant Parser as yyparse()
    participant Stack as Parse Stack

    User->>Lexer: Type: (2 + 3) * 4

    Lexer->>Parser: Token: '('
    Parser->>Stack: Shift '('

    Lexer->>Parser: Token: NUMBER(2)
    Parser->>Stack: Shift NUMBER(2)
    Parser->>Stack: Reduce: NUMBER → expr(2)

    Lexer->>Parser: Token: '+'
    Parser->>Stack: Shift '+'

    Lexer->>Parser: Token: NUMBER(3)
    Parser->>Stack: Shift NUMBER(3)
    Parser->>Stack: Reduce: NUMBER → expr(3)

    Parser->>Stack: Reduce: expr(2) + expr(3) → expr(5)

    Lexer->>Parser: Token: ')'
    Parser->>Stack: Reduce: '(' expr(5) ')' → expr(5)

    Lexer->>Parser: Token: '*'
    Parser->>Stack: Shift '*'

    Lexer->>Parser: Token: NUMBER(4)
    Parser->>Stack: Shift NUMBER(4)
    Parser->>Stack: Reduce: NUMBER → expr(4)

    Parser->>Stack: Reduce: expr(5) * expr(4) → expr(20)

    Lexer->>Parser: Token: '\n'
    Parser->>User: Print: 20
```

### Parse Stack Visualization

The parser uses a **stack** to keep track of what it has seen:

```mermaid
graph TB
    subgraph "Stack Evolution for (2 + 3) * 4"
        direction TB
        A["Step 1: ("] --> B["Step 2: ( 2"]
        B --> C["Step 3: ( expr(2)"]
        C --> D["Step 4: ( expr(2) +"]
        D --> E["Step 5: ( expr(2) + 3"]
        E --> F["Step 6: ( expr(2) + expr(3)"]
        F --> G["Step 7: ( expr(5)"]
        G --> H["Step 8: expr(5)"]
        H --> I["Step 9: expr(5) *"]
        I --> J["Step 10: expr(5) * 4"]
        J --> K["Step 11: expr(5) * expr(4)"]
        K --> L["Step 12: expr(20)"]
    end

    style A fill:#ffe1e1
    style L fill:#e1ffe1
```

### Parsing Actions Explained

1. **Shift**: Push token onto stack (save for later)
2. **Reduce**: Replace top of stack with a grammar rule's left side
   - Example: Replace `NUMBER` with `expr`
   - Example: Replace `expr + expr` with `expr`

---

## How Values Flow Through the System

### The Value Semantic Stack

Yacc maintains a **semantic value stack** parallel to the token stack. This holds the actual values.

```mermaid
graph TD
    subgraph "Token Stack"
        A1[expr]
        A2[*]
        A3[expr]
    end

    subgraph "Value Stack (YYSTYPE)"
        B1[20.0]
        B2[unused]
        B3[4.0]
    end

    A1 -.corresponds to.-> B1
    A2 -.corresponds to.-> B2
    A3 -.corresponds to.-> B3

    C["Reduce: expr * expr<br/>Action: $$ = $1 * $3<br/>$$ = 20.0 * 4.0 = 80.0"]

    A1 --> C
    A2 --> C
    A3 --> C
    B1 --> C
    B3 --> C

    C --> D[Result: expr with value 80.0]

    style A1 fill:#e1f5ff
    style A3 fill:#e1f5ff
    style B1 fill:#fff4e1
    style B3 fill:#fff4e1
    style C fill:#ffe1f5
    style D fill:#e1ffe1
```

### YYSTYPE: The Value Type

```c
#define YYSTYPE double
```

This tells Yacc that all semantic values are `double` (floating-point numbers).

- When lexer sets `yylval = 3.14`, it's setting a double
- When parser uses `$1`, it's accessing a double
- When action does `$$ = $1 + $3`, it's computing with doubles

### Complete Data Flow

```mermaid
flowchart TB
    A["Input String:<br/>'2 + 3'"] --> B[yylex reads '2']
    B --> C["yylex sets:<br/>yylval = 2.0"]
    C --> D["yylex returns:<br/>NUMBER token"]
    D --> E["Parser shifts:<br/>NUMBER onto stack"]
    E --> F["Parser pushes:<br/>2.0 onto value stack"]

    F --> G["Parser reduces:<br/>NUMBER → expr"]
    G --> H["Value 2.0 stays<br/>in value stack"]

    H --> I["... same for '+'<br/>and NUMBER(3) ..."]

    I --> J["Parser reduces:<br/>expr '+' expr"]
    J --> K["Action: $$ = $1 + $3<br/>$$ = 2.0 + 3.0"]
    K --> L["Push result 5.0<br/>onto value stack"]

    L --> M["Match: list expr '\\n'<br/>$2 = 5.0"]
    M --> N["Action: printf $2"]
    N --> O["Output: 5"]

    style A fill:#e1f5ff
    style C fill:#fff4e1
    style K fill:#ffe1f5
    style O fill:#e1ffe1
```

---

## Advanced Concepts

### Error Handling

When the parser encounters invalid input:

```c
void yyerror(const char *s)
{
    fprintf(stderr, "%s: %s near line %d\n", progname, s, lineno);
}
```

Example error:
```
Input:  2 + + 3
Output: hoc: syntax error near line 1
```

The parser calls `yyerror()` when it receives tokens that don't match any grammar rule.

### Line Number Tracking

```c
int lineno = 1;  // Global variable

// In yylex():
if (c == '\n') lineno++;
```

This allows error messages to show which line has the problem.

### Main Program Flow

```mermaid
graph TB
    A[main starts] --> B[progname = argv0]
    B --> C[yyparse called]
    C --> D{yyparse calls yylex}
    D -->|Has input| E[yylex returns token]
    E --> F[yyparse processes token]
    F --> D
    D -->|EOF reached| G[yyparse returns]
    G --> H[Program exits]

    F -.Error?.- I[Call yyerror]
    I --> D

    F -.Match print rule?.- J[printf result]
    J --> D

    style A fill:#e1f5ff
    style C fill:#fff4e1
    style E fill:#ffe1f5
    style H fill:#e1ffe1
```

### The Complete Picture

```mermaid
flowchart TB
    subgraph "HOC Calculator System"
        direction TB

        subgraph "Input Layer"
            A[User Types Expression]
        end

        subgraph "Lexical Analysis"
            B[yylex reads characters]
            C[Identifies token type]
            D[Sets yylval for NUMBER]
            E[Returns token to parser]
        end

        subgraph "Syntax Analysis"
            F[yyparse receives token]
            G[Shift or Reduce decision]
            H[Execute grammar rule action]
        end

        subgraph "Evaluation"
            I[Perform arithmetic]
            J[Push result to value stack]
        end

        subgraph "Output Layer"
            K[Print result]
        end

        A --> B
        B --> C
        C --> D
        D --> E
        E --> F
        F --> G
        G --> H
        H --> I
        I --> J
        J --> G
        G -.Final result.-> K
        K -.Ready for next.-> A
    end

    style A fill:#e1f5ff
    style B fill:#fff4e1
    style F fill:#ffe1f5
    style I fill:#ffd93d
    style K fill:#e1ffe1
```

---

## Key Takeaways

### For Beginners

1. **Lexer** (yylex): Breaks input into tokens
   - Like cutting a sentence into words

2. **Parser** (yyparse): Checks grammar and evaluates
   - Like understanding sentence structure and meaning

3. **Grammar Rules**: Define what's valid
   - Like the rules of English grammar

4. **Semantic Actions**: What to do when rules match
   - The actual calculations: `$$ = $1 + $3`

5. **Value Flow**: yylval → $1/$2/$3 → $$
   - How numbers travel through the system

### How It All Works Together

```
User types: 2 + 3 * 4

1. Lexer breaks it into: [NUMBER(2), '+', NUMBER(3), '*', NUMBER(4), '\n']

2. Parser builds tree respecting precedence:
         +
        / \
       2   *
          / \
         3   4

3. Evaluation (bottom-up):
   - 3 * 4 = 12
   - 2 + 12 = 14

4. Output: 14
```

### Why This Architecture?

- **Separation of Concerns**: Lexer doesn't know grammar, parser doesn't know characters
- **Maintainability**: Change grammar without rewriting lexer
- **Reusability**: Yacc can generate parsers for any grammar
- **Correctness**: Yacc handles complex cases automatically

---

## Practice Exercises

### Exercise 1: Trace This Expression
Trace `5 - 2 - 1` step by step. What's the result? Why?

<details>
<summary>Answer</summary>

Result: 2

Explanation: Left-associative means `(5 - 2) - 1 = 3 - 1 = 2`, not `5 - (2 - 1) = 5 - 1 = 4`
</details>

### Exercise 2: Precedence Challenge
What's the result of `2 + 3 * 4 - 6 / 2`?

<details>
<summary>Answer</summary>

Result: 11

Evaluation:
1. `3 * 4 = 12` (multiplication first)
2. `6 / 2 = 3` (division first)
3. `2 + 12 = 14` (left to right)
4. `14 - 3 = 11` (left to right)
</details>

### Exercise 3: What Happens Here?
Input: `2 + (3 * 4`

What happens? Why?

<details>
<summary>Answer</summary>

Error: "syntax error"

Missing closing parenthesis. Parser expects ')' but gets '\n' or EOF.
</details>

---

## Conclusion

The HOC calculator demonstrates fundamental concepts in language processing:

- **Tokenization**: Breaking input into meaningful pieces
- **Parsing**: Checking structure and building representations
- **Evaluation**: Computing results from structured representations
- **Tool-Assisted Development**: Using Yacc to generate complex code

These same principles apply to:
- Programming language compilers (C, Java, Python)
- Query languages (SQL)
- Markup languages (HTML, XML)
- Configuration files (JSON, YAML)

Understanding HOC gives you the foundation to build more complex language processors!

---

## Further Reading

- **Dragon Book**: "Compilers: Principles, Techniques, and Tools" by Aho, Lam, Sethi, Ullman
- **Yacc Documentation**: GNU Bison manual
- **Flex & Bison**: "flex & bison" by John Levine
- **Practice**: Try extending HOC with functions like `sin()`, `cos()`, or variables!
